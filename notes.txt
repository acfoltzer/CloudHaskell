
compilng as dynamic requires
  cabal install --enable-shared --reinstall binary
compilng as profiling requires
  cabal install -p --reinstall binary
for each dependency and
  ghc --make Test -dynamic
for the main.
run profiler as +RTS -p -RTS

x. TaskM mock-up with k-means
3. write-up
4. understand Erlang's global
6. Easier Amazon launching, easier local network launching


imagine the case that a node crashes and restarts on the same port; how then shall we distinguish the processes of the new node fromthe old one? I therefore propose that NodeIds and ProcessIds be extended with an additional value, storing perhaps random value or the time that the node was started; The Rmt!! messages should contain complete Pid, not just LocalPid; receive will then check that the message was sent to the right node. This is especially important if I use the extended NodeId format that contains unique time of creation


autogenerate graph of data dependencies - displayable with GnuPlot or whatever

to investigate: CML's first-class events; dynamics in Clean; "death by accidental complexity"; state charts; linear types; talk to Calvert about cost model of distributed computing; "session types" by Honda, AKA "communication types" by Nielson
investigate LinearML, Idris, 

setting up to use amazon EC2 or other cloud-systems, 

GlobalService maintains a list of active locks with their owners. Locks are acquired in a roundtrip conversation. Attempts to reacquire the same lock succeed. Attempt of another process to acquire the same lock fails.
A global lock is set by sending a lock broadcast to all known peers. If any of the peers fails, try again after a random backoff.
To perform a global update: get a list of known nodes, set a lock, get another list of known nodes, and make sure they are the same (otherwise restart). This has the effect of serializing updates with node addings. Then broadcast the name update and release the lock.

Near future
-------------
clean up cheaty mkName in Remote.Call where possible

the foldl'-based code for receiving messages can be made more efficient by writing a custom foldl replacement

demo applications (k-means, convex hull, string alignment,Byzantine generals, GRIP graph reduction, binomial option pricing)
limit use of SomeException. Create an "ignoreException" that throws out result, otherwise convert EsomException to something more precise
document command lines; document getting setup on Amazon
completely async send, returns ().

admin services aren't very secure: sending them a bad message can crash them, as can happen when running different versions; more say behavior would be nice
make LogConfig Show/Read so we can stick it in the config file
improve logging output, so that timestamp is only output at minute intervals and timestamp is properly aligned
have queryDiscovery send its query several times with a delay inbetween
let each Process have a "termination reason" set at exit, which can be retrieved by waitForProcess
sanity check to make sure that hostname and netmagic don't contain spaces
when doing a remote spawn, the per-process logging variable should cause logging to be forwarded to caling terminal
performance analysis service
more flexible spawning options: start in paused state; logging forwarding; autolink; automonitor

Tweaks:
------
I Question the necessity of having a separate ping process for each monitored node. It's probably better if each node has a single pingreceipt process and a pingsender process. Pingsender keeps track of all nodes that are monitoring that node and sends their pings together. Pingreceipt expects to receive a ping from every node that is being watched within a particular timeframe.
remove unecessary Pld specification from roundtripReceive
move all the random message type definitions and their instances to a separate module
instead of using Network.listenOn, I should use the lower level API to bind the particular interface named in Node.ndHostName, rather than the default interface
add exception handling wrapper to listenAndDeliver, as well as within it: e.g. handleCommSafer should catch exceptions and report to logger
use withSocketsDo for Windows compatibility
multiple logging strategies: to local file, by message to process, by message to a given node; use mvar to prevent race condition
timeout-bound variation of roundtrip suite
fail in ProcessM should throw an exception; fail in MatchM undo message acceptance???
Rename Lookup (and associated stuff) to CompiletimeMetadata or some such

Performance:
------------
use foldl'/foldr in receive to make pattern matching faster/stricter: http://www.haskell.org/haskellwiki/Stack_overflow  http://www.haskell.org/haskellwiki/Foldr_Foldl_Foldl'
exclusionList, of all things, consumes enormous memory and processor time when list is big; it shouldn't, I should restructure this
threadpool in listenAndDeliver, instead of forkIO on accept; this is probably not necessary
keep connections open and re-use them on a per-process basis; if I do this, maybe turn KeepAlive off
short-circuit sendRaw to deliver directly to queue when sending to localhost; this probably means a new Message type that can store unencoded messages. data Payload = PayloadEncoded ByteString | PayloadUnencoded a


Future work:
------------
STRef-like process-local variables, process-local storage
support for user-defined signals, beyond SigProcessUp/Down
Logload monitor should be able to keep track of # threads, CPU load, report to central; this can be done in Ping/Echo
higher level abstractions: replace ProcessM with a class that encapsulates its primitives (whatever they may be), so that one could implement a similar system based on other? remote protoocls. Eg an AllocatorM class that depends on ProcessM
testing with Test.QuickCheck and (mainly) HUnit
use ZeroConf/Bonjour to let nodes on a particular network find each other
proper commenting and documenation Haddock
elegant way to handle serializing infinite data structures
ability to serialize recursive data structures, e.g. tie-the-knot
how to serialize GADTs/existentials




One can invision multi-type message receiving operating under several ways:

a. The typename could be serialized as well, and checked by the receiver in a case statement
b. Each message would be accompanied by a user-determined string, which would be used in the case statement
c. Or some kind of clever clever SYB-style alteration system, e.g.: (receive (do ...) :: Foobar) |$| (receive (do ...):: (Int,String)) where a failed match would pass on to the next pattern. The corresponding type could be passed directly to the deserializer or could be matched against the typename explicitly transmitted


----------------
Removed code:

instance Monad ProcessM where
    m >>= k = ProcessM $ (runProcessM m) >>= (\x -> runProcessM (k x))
    return x = ProcessM $ return x


match :: (Serializable a) => MatchM a
match = (\id -> do (payload,lookup) <- ask
                   case decode lookup payload of
                      Nothing -> fail "No match"
                      Just x -> return x
                   ) id





type ClosureFunction = String

data ClosureArgs v = ClosureArg v (ClosureArgs v)| ClosureNoArg --this needs to be a GADT, otherwise stuck being homogenous
--how to serialize GADTs?

data Closure a = Closure ClosureFunction ClosureArgs
     deriving (Data,Typeable)
 
makeClosure0 :: ClosureFunction -> Closure a
makeClosure0 f = Closure f ClosureNoArg

makeClosure1 :: (Serializable v) => ClosureFunction -> v -> Closure a
makeClosure1 f v = Closure f (ClosureArg v ClosureNoArg)

makeClosure2 :: (Serializable v1,Serializable v2) => ClosureFunction -> v1 -> v2 -> Closure a
makeClosure2 f v1 v2 = Closure f (ClosureArg v1 (ClosureArg v2 ClosureNoArg))

invokeClosure :: (Typeable a) => Closure a -> ProcessM (Maybe a)
invokeClosure (Closure name arg) = (\id ->
                do p <- getProcess
                   node <- liftIO $ readMVar (prNodeRef p)
                   res <- sequence [pureFun node,ioFun node,procFun node]
                   case catMaybes res of
                      (a:b) -> return $ Just a
                      _ -> return Nothing ) id
   where pureFun node = case getEntryByIdent (ndLookup node) name of
                          Nothing -> return Nothing
                          Just x -> return $ Just $ apply x arg
         ioFun node =   case getEntryByIdent (ndLookup node) name of
                          Nothing -> return Nothing
                          Just x -> liftIO (apply x arg) >>= (return.Just)
         procFun node = case getEntryByIdent (ndLookup node) name of
                          Nothing -> return Nothing
                          Just x -> (apply x arg) >>= (return.Just)
         apply fun ClosureNoArg = fun
         apply fun (ClosureArg v next) = apply (fun v) next




Limitations:
------------

Polymorphic functions don't work in remoteCall blocks. I recommend writing wrappers for each instance of each polymorphic function e.g.

myMap :: (Int -> String) -> [Int] -> [String]
myMap = map


Process options:
---------------

forkIO vs forkOS
Erlang-style linkage, ping frequency
process style: synchronized return, pure functional invoke with asynch response, IO invoke, periodic invoke, persistent process (with channel), persistent with single-type channel, persistent with multi-type channel

Things to talk about in write-up
--------------------------------
Auto-generated closure stubs. Default generation precludes partial application, but this can be gotten around by using type aliases or doing closure packaging yourself.
Side-by-side comparison of Erlang code and Erlang-like Haskell code
discussion of programming with untyped processes vs typed channels. whither typed pids?
call of sufficiently stable StableName makes automatic mapping of real functions to their names very hard
SPJ's vision of multiple "threads" swimming within each "process", or my vision of a group of processes that must exist on the same node
how to serialize exisential types?

